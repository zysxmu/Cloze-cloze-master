{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理字词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import string\n",
    "import re\n",
    "import copy\n",
    "import math\n",
    "import nltk  \n",
    "import nltk.data \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正则表达式部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 得到所有文章的字符串\n",
    "raw = ''\n",
    "\n",
    "paths = glob.glob('./Training_Data/*.TXT')\n",
    "for path in paths:\n",
    "    raw += open(path).read()\n",
    "\n",
    "\n",
    "def splitSentence(paragraph):  \n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')  \n",
    "    sentences = tokenizer.tokenize(paragraph)  \n",
    "    return sentences  \n",
    "  \n",
    "if __name__ == '__main__': \n",
    "    # 删除括号和括号之间的内容\n",
    "    raw = re.sub(\"\\(.*?\\)|\\(|\\)|\\{.*?}|\\{|\\}|\\[.*?]|\\[|\\]\",'', raw)\n",
    "    \n",
    "    # 多个 *+\\n 变成 .\\n\n",
    "    raw = re.sub(\"\\*+\",r'.', raw)\n",
    "    \n",
    "    # 多个.\\n\\n+ 变成 .\\n\n",
    "    raw = re.sub(r\"\\.\\n\\n+\",r'.\\n', raw)\n",
    "    \n",
    "    # 多个 \\n\\n+ 变成 .\n",
    "    raw = re.sub(r\"\\n\\n+\",r'. ', raw)\n",
    "    \n",
    "    raw = raw.replace('\\n',' ')\n",
    "    \n",
    "    #print(raw[:100],len(raw))\n",
    "    sentences = splitSentence(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特殊字符和标点符号部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 移除含有特殊字符的句子\n",
    "special_symbol = '@#$%^&*_+-=;:\\\"\\'<>/~`'\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    for letter in special_symbol:\n",
    "        if letter in sentences[i]:\n",
    "            sentences.pop(i)\n",
    "\n",
    "# 标点符号变成' '\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    for letter in '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~':\n",
    "        sentences[i] = sentences[i].replace(letter,' ')\n",
    "\n",
    "          \n",
    "# 去除前后的空格\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    sentences[i] = sentences[i].strip()\n",
    "    \n",
    "# 去除前后的'.'\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    sentences[i] = sentences[i].strip('.')\n",
    "    \n",
    "# 去除前后的空格\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    sentences[i] = sentences[i].strip()\n",
    "\n",
    "         \n",
    "# 如果全部不全是数字或者字母，就删除\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    if re.sub(r\" \",r'', sentences[i]).isalnum() == False:\n",
    "        sentences.pop(i)\n",
    "\n",
    "\n",
    "# 多个空格转一个空格\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    sentences[i] = re.sub(r\" +\",r' ', sentences[i])\n",
    "    \n",
    "# 去除前后的空格\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    sentences[i] = sentences[i].strip()\n",
    "\n",
    "\n",
    "# 移除长度小于6的句子\n",
    "for i in range(len(sentences)-1,-1,-1):\n",
    "    if len(sentences[i].split(' ')) < 6:\n",
    "        sentences.pop(i)\n",
    "print('total sentences: ',len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('train-sentences.txt','w')\n",
    "for sentence in sentences:\n",
    "    f.write(sentence.lower()+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dev set for n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-gram dev集准备，把答案替换入句子中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev = open('./development_set.txt').read()\n",
    "\n",
    "dev = re.sub(r\"\\n\\n\\n\",'#', dev)\n",
    "\n",
    "dev_questions = dev.split('#')\n",
    "print(len(dev_questions))\n",
    "dev_questions = dev_questions[0:-1]\n",
    "print(len(dev_questions))\n",
    "\n",
    "write_out_list = []\n",
    "\n",
    "for dev_question in dev_questions:\n",
    "    \n",
    "    question_num = dev_question[:dev_question.find(')')]\n",
    "    \n",
    "    question = dev_question[dev_question.find(' ')+1:dev_question.find('\\n')]\n",
    "    \n",
    "    \n",
    "    a_answer = dev_question[dev_question.find('a)')+3:dev_question.find('\\n',dev_question.find('a)')+3)]\n",
    "    b_answer = dev_question[dev_question.find('b)')+3:dev_question.find('\\n',dev_question.find('b)')+3)]\n",
    "    c_answer = dev_question[dev_question.find('c)')+3:dev_question.find('\\n',dev_question.find('c)')+3)]\n",
    "    d_answer = dev_question[dev_question.find('d)')+3:dev_question.find('\\n',dev_question.find('d)')+3)]\n",
    "    e_answer = dev_question[dev_question.find('e)')+3:]\n",
    "    \n",
    "    \n",
    "    write_out_list.append(question_num)\n",
    "    write_out_list.append(question.replace('_____',a_answer))\n",
    "    write_out_list.append(question.replace('_____',b_answer))\n",
    "    write_out_list.append(question.replace('_____',c_answer))\n",
    "    write_out_list.append(question.replace('_____',d_answer))\n",
    "    write_out_list.append(question.replace('_____',e_answer))\n",
    "    \n",
    "\n",
    "# 标点符号变成' '\n",
    "for i in range(len(write_out_list)-1,-1,-1):\n",
    "    for letter in string.punctuation:\n",
    "        write_out_list[i] = write_out_list[i].replace(letter,' ')\n",
    "\n",
    "# 多个' '变一个' '，去掉前后的' '\n",
    "for i in range(len(write_out_list)):\n",
    "    write_out_list[i] = re.sub(' +',' ',write_out_list[i])\n",
    "    write_out_list[i] = write_out_list[i].strip() \n",
    "# 变成小写\n",
    "for i in range(len(write_out_list)-1,-1,-1):\n",
    "    write_out_list[i] = write_out_list[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('dev-sentences.txt','w')\n",
    "for sentence in write_out_list:\n",
    "    f.write(sentence+\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
